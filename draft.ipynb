{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "042e7e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robot ip is: 192.168.1.19\n",
      "try to find type and value of fx \n",
      " <class 'float'> 646.495\n",
      "try to find type and value of translation_vector \n",
      " <class 'list'> [[-0.05578176, -0.99668141, -0.0592837], [0.99840848, -0.05518776, -0.01161139], [0.00830112, -0.05983705, 0.99817364]] <class 'list'> [0.99840848, -0.05518776, -0.01161139]\n",
      "3\n",
      "[[-0.05578176 -0.99668141 -0.0592837 ]\n",
      " [ 0.99840848 -0.05518776 -0.01161139]\n",
      " [ 0.00830112 -0.05983705  0.99817364]]\n"
     ]
    }
   ],
   "source": [
    "from config.loader import load_config\n",
    "import numpy as np\n",
    "\n",
    "# 加载配置\n",
    "config = load_config()\n",
    "\n",
    "# 访问配置项\n",
    "db_host = config['robot_ip']\n",
    "fx = config['DEPTH_INTR']['fx']\n",
    "translation_vector = config['rotation_matrix']\n",
    "\n",
    "print(f\"robot ip is: {db_host}\")\n",
    "print('try to find type and value of fx', '\\n', type(fx), fx)\n",
    "print('try to find type and value of translation_vector', '\\n', type(translation_vector), translation_vector, type(translation_vector[1]), translation_vector[1])\n",
    "print(len(translation_vector))\n",
    "print(np.array(translation_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "488c9d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current c api version:  1.0.6\n",
      "1\n",
      "{'joint': [-0.0010000000474974513, 0.0, 0.0, 0.0020000000949949026, -0.0010000000474974513, 0.0010000000474974513], 'pose': [3e-06, 0.0, 0.8677, 0.0, 0.0, 3.141], 'err': {'err_len': 1, 'err': ['0x0000']}}\n",
      "<Robotic_Arm.rm_ctypes_wrap.rm_matrix_t object at 0x7f1a4ee4af40>\n",
      "[3.000000106112566e-06, 0.0, 0.8676999807357788, 0.0, 0.0, 3.1410000324249268] <class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Robotic_Arm.rm_robot_interface import *\n",
    "\n",
    "# 实例化RoboticArm类\n",
    "arm = RoboticArm(rm_thread_mode_e.RM_TRIPLE_MODE_E)\n",
    "\n",
    "# 创建机械臂连接，打印连接id\n",
    "handle = arm.rm_create_robot_arm(\"192.168.110.119\", 8080)\n",
    "print(handle.id)\n",
    "\n",
    "a, b = arm.rm_get_current_arm_state()\n",
    "print(b)\n",
    "pose = b['pose']\n",
    "mat = arm.rm_algo_pos2matrix(pose)\n",
    "print(mat)\n",
    "out = arm.rm_algo_matrix2pos(mat)\n",
    "print(out, type(out))\n",
    "\n",
    "\n",
    "arm.rm_delete_robot_arm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa0ee20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current c api version:  1.0.6\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "from func01 import pixel_to_camera_coord\n",
    "from Robotic_Arm.rm_robot_interface import *\n",
    "import time\n",
    "\n",
    "# 实例化RoboticArm类\n",
    "arm = RoboticArm(rm_thread_mode_e.RM_TRIPLE_MODE_E)\n",
    "\n",
    "# 创建机械臂连接，打印连接id\n",
    "handle = arm.rm_create_robot_arm(\"192.168.110.118\", 8080)\n",
    "# print(handle.id)\n",
    "init_pose = [-0.20807, 0.000295, 0.488525, 3.142, 0.326, 0.001]\n",
    "init1 = [-0.20807, 0.000295, 0.488525, 3.142, 0, 0]\n",
    "\n",
    "# 初始化管道\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)  # RGB流\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)  # 深度流\n",
    "\n",
    "# config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 6)  # RGB流\n",
    "# config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 6)  # 深度流\n",
    "\n",
    "pipeline.start(config)\n",
    "align = rs.align(rs.stream.color)\n",
    "\n",
    "# 鼠标回调函数\n",
    "depth_scale = None\n",
    "point_selected = False\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global depth_scale, point_selected, arm, pose_collect\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # 获取深度帧\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)\n",
    "        depth_frame = aligned_frames.get_depth_frame()\n",
    "        \n",
    "        # 获取深度比例因子\n",
    "        if depth_scale is None:\n",
    "            depth_sensor = pipeline.get_active_profile().get_device().first_depth_sensor()\n",
    "            depth_scale = depth_sensor.get_depth_scale()\n",
    "        \n",
    "        # 获取深度值（米）\n",
    "        depth_m = depth_frame.get_distance(x, y)\n",
    "        # print('depth scale', depth_scale)\n",
    "        # depth_m = depth_frame.get_distance(x, y) * depth_scale\n",
    "        print(f\"深度值（米）: {depth_m:.3f}\")\n",
    "        \n",
    "        # 获取RGB内参\n",
    "        color_profile = pipeline.get_active_profile().get_stream(rs.stream.color).as_video_stream_profile().get_intrinsics()\n",
    "        fx = color_profile.fx\n",
    "        fy = color_profile.fy\n",
    "        cx = color_profile.ppx\n",
    "        cy = color_profile.ppy\n",
    "        # 坐标转换, 相机坐标系坐标\n",
    "        Xc = (x - cx) / fx * depth_m\n",
    "        Yc = (y - cy) / fy * depth_m\n",
    "        Zc = depth_m\n",
    "        point_cam = np.array([Xc, Yc, Zc])\n",
    "\n",
    "\n",
    "        # 转换成机械臂基坐标系下的坐标\n",
    "        R_cam_base = np.array(  [[-0.00310044 , 0.99999236 , 0.00238261],\n",
    "                                [ -0.99997374 ,-0.00311597  ,0.00654238],\n",
    "                                [ 0.00654975 ,-0.00236226 , 0.99997576]])\n",
    "        t_cam_base = np.array( [[-0.09674632,0.03282877,0.0294021 ]])\n",
    "        point_base = R_cam_base @ point_cam + t_cam_base\n",
    "        point_base = np.array(point_base, dtype=np.float32).reshape(3, 1)\n",
    "        # print(type(point_base), np.shape(point_base))\n",
    "        a, b = arm.rm_get_current_arm_state()\n",
    "        pose = b['pose']\n",
    "        joint = b['joint']\n",
    "        # print(pose)\n",
    "        mat = arm.rm_algo_pos2matrix(pose)\n",
    "        # print(mat)\n",
    "        mat = np.array(mat.data, dtype=np.float32).reshape(4, 4)\n",
    "        rot, vec = mat[:3, :3], mat[:3, -1].reshape(1, 3)\n",
    "        # print(type(rot), np.shape(rot), type(vec), np.shape(vec))\n",
    "\n",
    "        point_base = rot.dot(point_base)\n",
    "        point_base = point_base.reshape(1, 3)\n",
    "        point_base += vec\n",
    "        \n",
    "        # print(f\"像素坐标： ({x}, {y})\")\n",
    "        # print(f\"相机坐标系坐标: ({Xc:.3f}, {Yc:.3f}, {Zc:.3f})\")\n",
    "        print(f'机械臂基坐标系下坐标： ({point_base})')\n",
    "        pose1 = init1.copy()\n",
    "        for i in range(3):\n",
    "            pose1[i] = point_base[0][i]\n",
    "        error_code, new_joint = arm.rm_algo_inverse_kinematics(rm_inverse_kinematics_params_t(joint, pose1, 1))\n",
    "        if error_code != 0:\n",
    "            print('fail to do inverse calculation')\n",
    "        else:\n",
    "            print('inverse calculation succeed!')\n",
    "            print(new_joint)\n",
    "            new_joint = arm.rm_algo_cartesian_tool(new_joint, 0, 0, -0.05)\n",
    "            print(new_joint)\n",
    "            print(arm.rm_movej_p(new_joint, 10, 0, 0, 1))\n",
    "            time.sleep(10)\n",
    "            print(arm.rm_movej_p(init_pose, 20, 0, 0, 1))\n",
    "        point_selected = True\n",
    "\n",
    "# 创建窗口并绑定回调\n",
    "cv2.namedWindow('RGB & Depth')\n",
    "cv2.setMouseCallback('RGB & Depth', mouse_callback)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # 获取对齐后的帧\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "        depth_frame = aligned_frames.get_depth_frame()\n",
    "        \n",
    "        # 转换为numpy数组\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        # print('color_image', np.shape(color_image), 'depth_image', np.shape(depth_image))\n",
    "        \n",
    "        # 可视化深度图（彩色映射）\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        \n",
    "        # 合并显示RGB和彩色深度图\n",
    "        # combined_image = np.hstack((color_image, depth_image))\n",
    "        combined_image = np.hstack((color_image, depth_colormap))\n",
    "        \n",
    "        # 显示图像\n",
    "        cv2.imshow('RGB & Depth', combined_image)\n",
    "        # cv2.imshow('rbg', color_image)\n",
    "        # cv2.imshow('Depth', depth_image)\n",
    "        \n",
    "        if point_selected:\n",
    "            # 在图像上标记选中的点\n",
    "            # cv2.circle(color_image, (x, y), 5, (0, 255, 0), -1)\n",
    "            cv2.imshow('RGB & Depth', combined_image)\n",
    "            point_selected = False\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            arm.rm_delete_robot_arm()\n",
    "            break\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1039c8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050511621321113816\n"
     ]
    }
   ],
   "source": [
    "a = [-0.43634102 , 0.04662181 ,-0.00998363]\n",
    "b = [-0.43667188 ,-0.00388653 ,-0.00951245]\n",
    "\n",
    "out = ((a[0] - b[0])**2 + (a[1] - b[1])**2 + (a[2] - b[2])**2)**0.5\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba6d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current c api version:  1.0.6\n",
      "{'joint': [-0.10300000011920929, 0.9679999947547913, 45.44900131225586, 0.02800000086426735, 114.90599822998047, -0.14100000262260437], 'pose': [-0.208066, 0.0003, 0.488526, 3.142, 0.325, 0.001], 'err': {'err_len': 1, 'err': ['0x0000']}}\n",
      "[-0.208066, 0.0003, 0.488526, 3.142, 0.325, 0.001]\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from Robotic_Arm.rm_robot_interface import *\n",
    "\n",
    "# 实例化RoboticArm类\n",
    "arm = RoboticArm(rm_thread_mode_e.RM_TRIPLE_MODE_E)\n",
    "init = [-0.20807, 0.000295, 0.488525, 3.142, 0.326, 0.001]\n",
    "pose1 = [-0.5774, 0.0364, 0.1097, 0, 3.14, 0]\n",
    "pose2 = [-0.519493, -0.031722, 0.078806, -1.808, 1.21, 0.493]\n",
    "# 创建机械臂连接，打印连接id\n",
    "handle = arm.rm_create_robot_arm(\"192.168.110.118\", 8080)\n",
    "\n",
    "a, b = arm.rm_get_current_arm_state()\n",
    "print(b)\n",
    "pose = b['pose']\n",
    "print(pose)\n",
    "\n",
    "# print(arm.rm_movej_p(init, 20, 0, 0, 1))\n",
    "# print(arm.rm_movej_p(pose1, 10, 0, 0, 1))\n",
    "# print(arm.rm_movej_p(pose, 10, 0, 0, 1))\n",
    "print(arm.rm_movej([0,0,0,0,0,0], 20, 0, 0, 1))\n",
    "\n",
    "arm.rm_delete_robot_arm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ebc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d8541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c5955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1280x720  p[652.811 356.065]  f[913.225 911.32]  Inverse Brown Conrady [0 0 0 0 0] ] \n",
      " 913.2247314453125 911.320068359375 652.81103515625 356.0649719238281 [0. 0. 0. 0. 0.] \n",
      " [[913.22473   0.      652.81104]\n",
      " [  0.      911.32007 356.06497]\n",
      " [  0.        0.        1.     ]]\n",
      "[ 1280x720  p[637.515 358.546]  f[637.481 637.481]  Brown Conrady [0 0 0 0 0] ] \n",
      " 637.4808959960938 637.4808959960938 637.5151977539062 358.5460205078125 [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "\n",
    "# 初始化管道\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "# config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 6)\n",
    "# config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 6)\n",
    "pipeline.start(config)\n",
    "\n",
    "# 获取 RGB 相机内参\n",
    "color_frame = pipeline.wait_for_frames().get_color_frame()\n",
    "color_intrin = color_frame.profile.as_video_stream_profile().intrinsics\n",
    "fx, fy, cx, cy = color_intrin.fx, color_intrin.fy, color_intrin.ppx, color_intrin.ppy\n",
    "dist_coeffs = color_intrin.coeffs  # 畸变系数\n",
    "dist_coeffs = np.array(dist_coeffs)\n",
    "\n",
    "# 获取深度相机内参（与 RGB 共享）\n",
    "# depth_intrin = color_intrin  # D435i 的 RGB 和深度相机内参对齐\n",
    "\n",
    "depth_frame = pipeline.wait_for_frames().get_depth_frame()\n",
    "depth_intrin = depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "fx1, fy1, cx1, cy1 = depth_intrin.fx, depth_intrin.fy, depth_intrin.ppx, depth_intrin.ppy\n",
    "dist_coeffs1 = depth_intrin.coeffs  # 畸变系数\n",
    "dist_coeffs1 = np.array(dist_coeffs1)\n",
    "\n",
    "# 停止管道\n",
    "pipeline.stop()\n",
    "\n",
    "K = np.array([\n",
    "    [fx, 0, cx],\n",
    "    [0, fy, cy],\n",
    "    [0, 0, 1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(color_intrin, '\\n', fx, fy, cx, cy, dist_coeffs, '\\n', K)\n",
    "print(depth_intrin, '\\n', fx1, fy1, cx1, cy1, dist_coeffs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe519d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current c api version:  1.0.6\n",
      "1\n",
      "0\n",
      "(0, {'cycle': 50, 'enable': True, 'port': 8089, 'force_coordinate': 0, 'ip': '192.168.110.55', 'custom_config': {'joint_speed': 1, 'lift_state': 0, 'expand_state': 0, 'hand_state': 0, 'arm_current_status': 1, 'aloha_state': 0}})\n",
      "Current arm pose:  [0.014999999664723873, 0.03500000014901161, 0.210999995470047, 0.03799999877810478, 0.21400000154972076, 0.0010000000474974513, 0.0]\n",
      "Current arm pose:  [-0.006000000052154064, 2.5209999084472656, 5.122000217437744, -0.00800000037997961, 7.486999988555908, 0.0010000000474974513, 0.0]\n",
      "Current arm pose:  [-0.03400000184774399, 7.824999809265137, 15.63700008392334, -0.04800000041723251, 23.347000122070312, -0.0010000000474974513, 0.0]\n",
      "Current arm pose:  [-0.01899999938905239, 13.458999633789062, 26.958999633789062, -0.03700000047683716, 40.23699951171875, -0.0010000000474974513, 0.0]\n",
      "Current arm pose:  [-0.004000000189989805, 19.167999267578125, 38.34199905395508, -0.0020000000949949026, 57.513999938964844, 0.0, 0.0]\n",
      "Current arm pose:  [0.0, 24.731000900268555, 49.5, 0.004999999888241291, 74.03199768066406, -0.0010000000474974513, 0.0]\n",
      "Current arm pose:  [0.0, 28.945999145507812, 57.888999938964844, 0.004999999888241291, 86.72200012207031, 0.0, 0.0]\n",
      "Current arm pose:  [0.0020000000949949026, 29.97800064086914, 59.9370002746582, -0.0020000000949949026, 89.71499633789062, 0.0020000000949949026, 0.0]\n",
      "movej:  0\n",
      "Current arm pose:  [0.0010000000474974513, 30.0, 59.93000030517578, -0.0020000000949949026, 89.78700256347656, 0.0010000000474974513, 0.0]\n",
      "Current arm pose:  [0.0010000000474974513, 28.180999755859375, 56.25400161743164, -0.004000000189989805, 84.48999786376953, 0.0, 0.0]\n",
      "Current arm pose:  [-0.0010000000474974513, 23.07200050354004, 46.07500076293945, -0.0010000000474974513, 69.1719970703125, -0.0010000000474974513, 0.0]\n",
      "Current arm pose:  [0.0010000000474974513, 17.402000427246094, 34.80400085449219, 0.0020000000949949026, 52.34700012207031, 0.0, 0.0]\n",
      "Current arm pose:  [0.0020000000949949026, 11.800000190734863, 23.56399917602539, 0.0020000000949949026, 35.441001892089844, -0.0010000000474974513, 0.0]\n",
      "Current arm pose:  [0.010999999940395355, 6.014999866485596, 12.031000137329102, 0.006000000052154064, 18.097000122070312, 0.0, 0.0]\n",
      "Current arm pose:  [0.029999999329447746, 1.343000054359436, 2.7790000438690186, 0.03700000047683716, 4.105999946594238, 0.0020000000949949026, 0.0]\n",
      "movej:  0\n",
      "0\n",
      "(0, {'cycle': 50, 'enable': False, 'port': 8089, 'force_coordinate': 0, 'ip': '192.168.110.55', 'custom_config': {'joint_speed': 1, 'lift_state': 0, 'expand_state': 0, 'hand_state': 0, 'arm_current_status': 1, 'aloha_state': 0}})\n",
      "Time taken for the operation:  4.346430063247681\n",
      "1747726630.11262\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_0.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_1.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_2.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_3.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_4.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_5.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_6.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_7.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_8.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_9.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_10.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_11.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_12.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_13.jpg\n",
      "Saved c:\\Users\\admin\\Desktop\\internship\\try\\graspnet_rm65_poplar\\images\\image_14.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面是一个如何注册UDP机械臂实时状态主动上报信息回调函数的示例：\n",
    "# 在这个示例中，我们定义了一个名为`arm_state_func`的函数，用于处理机械臂实时上报的数据，并将其注册为回调函数。\n",
    "# `arm_state_func`函数会按照UDP接口设置的周期被调用，该函数接收一个rm_realtime_arm_joint_state_t的对象作为参数\n",
    "from Robotic_Arm.rm_robot_interface import *\n",
    "import keyboard\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyrealsense2 as rs\n",
    "import os\n",
    "\n",
    "def arm_state_func(data):\n",
    "    global pipeline, images\n",
    "    a = data.joint_status.to_dict()\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    images.append(color_image.copy())\n",
    "    print(\"Current arm pose: \", a['joint_position'])\n",
    "\n",
    "\n",
    "# 初始化为三线程模式\n",
    "arm = RoboticArm(rm_thread_mode_e.RM_TRIPLE_MODE_E)\n",
    "\n",
    "# 创建机械臂连接，打印连接id\n",
    "handle = arm.rm_create_robot_arm(\"192.168.110.119\", 8080)\n",
    "print(handle.id)\n",
    "\n",
    "# 设置UDP端口，广播周期500ms，使能，广播端口号8089，力数据坐标系使用传感器坐标系，上报目标IP为\"192.168.1.104\"\n",
    "# 自定义上报项均设置关闭，用户可根据实际情况修改这些配置\n",
    "custom = rm_udp_custom_config_t()\n",
    "custom.joint_speed = 1\n",
    "custom.lift_state = 0\n",
    "custom.expand_state = 0\n",
    "custom.arm_current_status = 1\n",
    "config = rm_realtime_push_config_t(50, True, 8089, 0, \"192.168.110.55\", custom)\n",
    "print(arm.rm_set_realtime_push(config))\n",
    "print(arm.rm_get_realtime_push())\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)  # RGB流\n",
    "profile = pipeline.start(config)\n",
    "frames = pipeline.wait_for_frames()\n",
    "images = []\n",
    "\n",
    "arm_state_callback = rm_realtime_arm_state_callback_ptr(arm_state_func)\n",
    "arm.rm_realtime_arm_state_call_back(arm_state_callback)\n",
    "\n",
    "start_time = time.time()\n",
    "# 关节运动\n",
    "ret = arm.rm_movej([0, 30, 60, 0, 90, 0], 30, 0, 0, 1)\n",
    "print(\"movej: \", ret)\n",
    "ret = arm.rm_movej([0, 0, 0, 0, 0, 0], 30, 0, 0, 1)\n",
    "print(\"movej: \", ret)\n",
    "\n",
    "config_end = rm_realtime_push_config_t(50, False, 8089, 0, \"192.168.110.55\", custom)\n",
    "print(arm.rm_set_realtime_push(config_end))\n",
    "print(arm.rm_get_realtime_push())\n",
    "end_time = time.time()\n",
    "print(\"Time taken for the operation: \", end_time - start_time)\n",
    "print(end_time)\n",
    "# 删除指定机械臂对象\n",
    "arm.rm_delete_robot_arm()\n",
    "# arm.rm_destory()\n",
    "foler = os.path.join(os.getcwd(), 'images')\n",
    "if not os.path.exists(foler):\n",
    "    os.makedirs(foler)\n",
    "for i, image in enumerate(images):\n",
    "    image_path = os.path.join(foler, f'image_{i}.jpg')\n",
    "    cv2.imwrite(image_path, image)\n",
    "    print(f\"Saved {image_path}\")\n",
    "\n",
    "arm.rm_destory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6f1cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camera_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
