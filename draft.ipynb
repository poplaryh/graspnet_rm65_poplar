{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "042e7e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robot ip is: 192.168.110.118\n",
      "try to find type and value of fx \n",
      " <class 'float'> 382.489\n",
      "try to find type and value of translation_vector \n",
      " <class 'list'> [-0.09674632, 0.03282877, 0.0294021] <class 'float'> 0.03282877\n",
      "3\n",
      "[[-0.00310044, 0.99999236, 0.00238261], [-0.99997374, -0.00311597, 0.00654238], [0.00654975, -0.00236226, 0.99997576]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00310044,  0.99999236,  0.00238261, -0.09674632],\n",
       "       [-0.99997374, -0.00311597,  0.00654238,  0.03282877],\n",
       "       [ 0.00654975, -0.00236226,  0.99997576,  0.0294021 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config.loader import load_config\n",
    "import numpy as np\n",
    "\n",
    "# 加载配置\n",
    "config = load_config()\n",
    "\n",
    "# 访问配置项\n",
    "db_host = config['robot_ip']\n",
    "fx = config['DEPTH_INTR']['fx']\n",
    "rotation_matrix = config['rotation_matrix']\n",
    "translation_vector = config['translation_vector']\n",
    "\n",
    "print(f\"robot ip is: {db_host}\")\n",
    "print('try to find type and value of fx', '\\n', type(fx), fx)\n",
    "print('try to find type and value of translation_vector', '\\n', type(translation_vector), translation_vector, type(translation_vector[1]), translation_vector[1])\n",
    "print(len(translation_vector))\n",
    "print(rotation_matrix)\n",
    "a = np.eye(4)\n",
    "a[:3, 3] = translation_vector\n",
    "a[:3, :3] = rotation_matrix\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "488c9d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current c api version:  1.0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Robotic_Arm.rm_robot_interface import *\n",
    "\n",
    "# 实例化RoboticArm类\n",
    "arm = RoboticArm(rm_thread_mode_e.RM_TRIPLE_MODE_E)\n",
    "\n",
    "# 创建机械臂连接，打印连接id\n",
    "handle = arm.rm_create_robot_arm(\"192.168.110.118\", 8080)\n",
    "pose = [0.3, 0, 0.3, 3.14, 0, 0]\n",
    "init = [0, 0, 0, 0, 0, 0]\n",
    "params = rm_inverse_kinematics_params_t(init, pose, 1)\n",
    "joint = arm.rm_algo_inverse_kinematics(params)\n",
    "# print(type(joint), type(joint[0]), joint)\n",
    "# a, b = arm.rm_get_current_arm_state()\n",
    "# print(b)\n",
    "# pose = b['pose']\n",
    "# mat = arm.rm_algo_pos2matrix(pose)\n",
    "# print(mat)\n",
    "# out = arm.rm_algo_matrix2pos(mat)\n",
    "# print(out, type(out))\n",
    "\n",
    "print(arm.rm_movej(init, 20, 0, 0 ,1))\n",
    "# print(arm.rm_movej_p(pose, 20, 0, 0, 1))\n",
    "# print(arm.rm_movej(init, 20, 0, 0 ,1))\n",
    "# print(arm.rm_movej(joint[1], 20, 0, 0 ,1))\n",
    "# print(arm.rm_movej(init, 20, 0, 0 ,1))\n",
    "\n",
    "arm.rm_delete_robot_arm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6483497f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current c api version:  1.0.6\n",
      "False\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "from Robotic_Arm.rm_robot_interface import *\n",
    "import numpy as np\n",
    "\n",
    "arm_model = rm_robot_arm_model_e.RM_MODEL_RM_65_E  # RM_65机械臂\n",
    "force_type = rm_force_type_e.RM_MODEL_RM_B_E  # 标准版\n",
    "# 初始化算法的机械臂及末端型号\n",
    "algo_handle = Algo(arm_model, force_type)\n",
    "\n",
    "# 将位姿转为旋转矩阵\n",
    "mat = algo_handle.rm_algo_pos2matrix([-0.177347, 0.438112, -0.215102, 2.09078, 0.942362, 2.39144])\n",
    "\n",
    "arm = RoboticArm(rm_thread_mode_e.RM_TRIPLE_MODE_E)\n",
    "mat1 = arm.rm_algo_pos2matrix([-0.177347, 0.438112, -0.215102, 2.09078, 0.942362, 2.39144])\n",
    "print(mat==mat1)\n",
    "a = np.array(mat.data)\n",
    "b = np.array(mat1.data)\n",
    "print(a==b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f0c049d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current c api version:  1.0.6\n",
      "the honogeneous matrix of robot end:  \n",
      " [[ 9.4174999e-01 -0.0000000e+00 -3.3631384e-01 -2.0187500e-01]\n",
      " [ 0.0000000e+00  1.0000000e+00 -0.0000000e+00  7.0000001e-06]\n",
      " [ 3.3631384e-01  0.0000000e+00  9.4174999e-01  5.9295797e-01]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00]]\n",
      "the honogeneous matrix of camera:  \n",
      " [[-0.00512261  0.94253726 -0.33406187 -0.30287418]\n",
      " [-0.99997374 -0.00311597  0.00654238  0.03283577]\n",
      " [ 0.00512551  0.33408662  0.94252847  0.58811027]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "the difference of height between camera and robot end:  \n",
      " -0.0048476993650734546\n",
      "相机朝下，需要旋转，请稍等\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Robotic_Arm.rm_robot_interface import *\n",
    "\n",
    "global arm\n",
    "arm = RoboticArm(rm_thread_mode_e.RM_TRIPLE_MODE_E)\n",
    "handle = arm.rm_create_robot_arm(\"192.168.110.118\", 8080)\n",
    "translation_vector = np.array([-0.09674632, 0.03282877, 0.0294021]) \n",
    "rotation_matrix = np.array([[-0.00310044 , 0.99999236 , 0.00238261],\n",
    "                  [-0.99997374 ,-0.00311597  ,0.00654238],\n",
    "                  [ 0.00654975 ,-0.00236226 , 0.99997576]])\n",
    "h_eye = np.array([[-0.00310044 , 0.99999236 , 0.00238261, -0.09674632],\n",
    "                  [-0.99997374 ,-0.00311597  ,0.00654238, 0.03282877],\n",
    "                  [ 0.00654975 ,-0.00236226 , 0.99997576, 0.0294021],\n",
    "                  [0, 0, 0, 1]])\n",
    "\n",
    "_, dic1 = arm.rm_get_current_arm_state()    \n",
    "current_joint, current_pose = dic1['joint'], dic1['pose']\n",
    "matrix = arm.rm_algo_pos2matrix(current_pose)\n",
    "h_current = np.array(matrix.data, dtype=np.float32).reshape(4, 4)\n",
    "r_current = h_current[:3, :3]\n",
    "pose_cam = h_current @ h_eye\n",
    "print('the honogeneous matrix of robot end: ', '\\n', h_current)\n",
    "print('the honogeneous matrix of camera: ', '\\n', pose_cam)\n",
    "judgement = pose_cam[2, -1] - h_current[2, -1]\n",
    "print('the difference of height between camera and robot end: ', '\\n', judgement)\n",
    "if judgement >= 0:\n",
    "    print('相机没有朝下，不用管它')\n",
    "else:\n",
    "    print('相机朝下，需要旋转，请稍等')\n",
    "    current_joint[-1] += 180\n",
    "    print(arm.rm_movej(current_joint, 20, 0, 0, 1))\n",
    "\n",
    "arm.rm_delete_robot_arm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fa0ee20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current c api version:  1.0.6\n",
      "深度值（米）: 0.527\n",
      "[-0.20807, 0.000295, 0.488525, 3.142, 0.326, 0.001]\n",
      "像素坐标： (480, 261)\n",
      "相机坐标系坐标: (0.131, 0.020, 0.527)\n",
      "机械臂基坐标系下坐标： ([[-0.45803362  0.09516113 -0.01514164]])\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "from func01 import pixel_to_camera_coord\n",
    "from Robotic_Arm.rm_robot_interface import *\n",
    "\n",
    "# 实例化RoboticArm类\n",
    "arm = RoboticArm(rm_thread_mode_e.RM_TRIPLE_MODE_E)\n",
    "\n",
    "# 创建机械臂连接，打印连接id\n",
    "handle = arm.rm_create_robot_arm(\"192.168.110.118\", 8080)\n",
    "# print(handle.id)\n",
    "pose_collect = []\n",
    "\n",
    "# 初始化管道\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)  # RGB流\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)  # 深度流\n",
    "\n",
    "# config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 6)  # RGB流\n",
    "# config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 6)  # 深度流\n",
    "\n",
    "pipeline.start(config)\n",
    "align = rs.align(rs.stream.color)\n",
    "\n",
    "# 鼠标回调函数\n",
    "depth_scale = None\n",
    "point_selected = False\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global depth_scale, point_selected, arm, pose_collect\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # 获取深度帧\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)\n",
    "        depth_frame = aligned_frames.get_depth_frame()\n",
    "        \n",
    "        # 获取深度比例因子\n",
    "        if depth_scale is None:\n",
    "            depth_sensor = pipeline.get_active_profile().get_device().first_depth_sensor()\n",
    "            depth_scale = depth_sensor.get_depth_scale()\n",
    "        \n",
    "        # 获取深度值（米）\n",
    "        depth_m = depth_frame.get_distance(x, y)\n",
    "        # print('depth scale', depth_scale)\n",
    "        # depth_m = depth_frame.get_distance(x, y) * depth_scale\n",
    "        print(f\"深度值（米）: {depth_m:.3f}\")\n",
    "        \n",
    "        # 获取RGB内参\n",
    "        color_profile = pipeline.get_active_profile().get_stream(rs.stream.color).as_video_stream_profile().get_intrinsics()\n",
    "        fx = color_profile.fx\n",
    "        fy = color_profile.fy\n",
    "        cx = color_profile.ppx\n",
    "        cy = color_profile.ppy\n",
    "        # 坐标转换, 相机坐标系坐标\n",
    "        Xc = (x - cx) / fx * depth_m\n",
    "        Yc = (y - cy) / fy * depth_m\n",
    "        Zc = depth_m\n",
    "        point_cam = np.array([Xc, Yc, Zc])\n",
    "\n",
    "\n",
    "        # 转换成机械臂基坐标系下的坐标\n",
    "        R_cam_base = np.array(  [[-0.00310044 , 0.99999236 , 0.00238261],\n",
    "                                [ -0.99997374 ,-0.00311597  ,0.00654238],\n",
    "                                [ 0.00654975 ,-0.00236226 , 0.99997576]])\n",
    "        t_cam_base = np.array( [[-0.09674632,0.03282877,0.0294021 ]])\n",
    "        point_base = R_cam_base @ point_cam + t_cam_base\n",
    "        point_base = np.array(point_base, dtype=np.float32).reshape(3, 1)\n",
    "        # print(type(point_base), np.shape(point_base))\n",
    "        a, b = arm.rm_get_current_arm_state()\n",
    "        pose = b['pose']\n",
    "        print(pose)\n",
    "        mat = arm.rm_algo_pos2matrix(pose)\n",
    "        # print(mat)\n",
    "        mat = np.array(mat.data, dtype=np.float32).reshape(4, 4)\n",
    "        rot, vec = mat[:3, :3], mat[:3, -1].reshape(1, 3)\n",
    "        # print(type(rot), np.shape(rot), type(vec), np.shape(vec))\n",
    "\n",
    "        point_base = rot.dot(point_base)\n",
    "        point_base = point_base.reshape(1, 3)\n",
    "        point_base += vec\n",
    "\n",
    "        pose_collect.append(point_base)\n",
    "        \n",
    "        print(f\"像素坐标： ({x}, {y})\")\n",
    "        print(f\"相机坐标系坐标: ({Xc:.3f}, {Yc:.3f}, {Zc:.3f})\")\n",
    "        print(f'机械臂基坐标系下坐标： ({point_base})')\n",
    "        point_selected = True\n",
    "\n",
    "# 创建窗口并绑定回调\n",
    "cv2.namedWindow('RGB & Depth')\n",
    "cv2.setMouseCallback('RGB & Depth', mouse_callback)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # 获取对齐后的帧\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "        depth_frame = aligned_frames.get_depth_frame()\n",
    "        \n",
    "        # 转换为numpy数组\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        # print('color_image', np.shape(color_image), 'depth_image', np.shape(depth_image))\n",
    "        \n",
    "        # 可视化深度图（彩色映射）\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        \n",
    "        # 合并显示RGB和彩色深度图\n",
    "        # combined_image = np.hstack((color_image, depth_image))\n",
    "        combined_image = np.hstack((color_image, depth_colormap))\n",
    "        \n",
    "        # 显示图像\n",
    "        cv2.imshow('RGB & Depth', combined_image)\n",
    "        # cv2.imshow('rbg', color_image)\n",
    "        # cv2.imshow('Depth', depth_image)\n",
    "        \n",
    "        if point_selected:\n",
    "            # 在图像上标记选中的点\n",
    "            # cv2.circle(color_image, (x, y), 5, (0, 255, 0), -1)\n",
    "            cv2.imshow('RGB & Depth', combined_image)\n",
    "            point_selected = False\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            arm.rm_delete_robot_arm()\n",
    "            break\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1039c8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050511621321113816\n"
     ]
    }
   ],
   "source": [
    "a = [-0.43634102 , 0.04662181 ,-0.00998363]\n",
    "b = [-0.43667188 ,-0.00388653 ,-0.00951245]\n",
    "\n",
    "out = ((a[0] - b[0])**2 + (a[1] - b[1])**2 + (a[2] - b[2])**2)**0.5\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0cba6d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current c api version:  1.0.6\n",
      "{'joint': [-0.10400000214576721, 0.968999981880188, 45.44900131225586, 0.02800000086426735, 114.90299987792969, -0.1379999965429306], 'pose': [-0.208079, 0.000305, 0.488523, 3.142, 0.325, 0.0], 'err': {'err_len': 1, 'err': ['0x0000']}}\n",
      "[-0.208079, 0.000305, 0.488523, 3.142, 0.325, 0.0]\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Move command result is: false, current Device: 0, trajectory_connect: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Robotic_Arm.rm_robot_interface import *\n",
    "\n",
    "# 实例化RoboticArm类\n",
    "arm = RoboticArm(rm_thread_mode_e.RM_TRIPLE_MODE_E)\n",
    "init = [-0.20807, 0.000295, 0.488525, 3.142, 0.326, 0.001]\n",
    "pose1 = [-0.5885288119316101, -0.23499751091003418, 0.14162935316562653, 3.15, 0.287, -0.045]\n",
    "\n",
    "# 创建机械臂连接，打印连接id\n",
    "handle = arm.rm_create_robot_arm(\"192.168.110.118\", 8080)\n",
    "\n",
    "a, b = arm.rm_get_current_arm_state()\n",
    "print(b)\n",
    "pose = b['pose']\n",
    "print(pose)\n",
    "\n",
    "print(arm.rm_movej_p(init, 20, 0, 0, 1))\n",
    "print(arm.rm_movej_p(pose1, 10, 0, 0, 1))\n",
    "print(arm.rm_movej_p(init, 20, 0, 0, 1))\n",
    "\n",
    "arm.rm_delete_robot_arm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6c5955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 640x480  p[328.541 237.377]  f[608.816 607.547]  Inverse Brown Conrady [0 0 0 0 0] ] \n",
      " 608.8164672851562 607.5466918945312 328.5406799316406 237.3766632080078 [0. 0. 0. 0. 0.] \n",
      " [[608.81647   0.      328.54068]\n",
      " [  0.      607.5467  237.37666]\n",
      " [  0.        0.        1.     ]]\n",
      "[ 640x480  p[318.509 239.128]  f[382.489 382.489]  Brown Conrady [0 0 0 0 0] ] \n",
      " 382.488525390625 382.488525390625 318.5091247558594 239.1276092529297 [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "\n",
    "# 初始化管道\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "# config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 6)\n",
    "# config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 6)\n",
    "pipeline.start(config)\n",
    "\n",
    "# 获取 RGB 相机内参\n",
    "color_frame = pipeline.wait_for_frames().get_color_frame()\n",
    "color_intrin = color_frame.profile.as_video_stream_profile().intrinsics\n",
    "fx, fy, cx, cy = color_intrin.fx, color_intrin.fy, color_intrin.ppx, color_intrin.ppy\n",
    "dist_coeffs = color_intrin.coeffs  # 畸变系数\n",
    "dist_coeffs = np.array(dist_coeffs)\n",
    "\n",
    "# 获取深度相机内参（与 RGB 共享）\n",
    "# depth_intrin = color_intrin  # D435i 的 RGB 和深度相机内参对齐\n",
    "\n",
    "depth_frame = pipeline.wait_for_frames().get_depth_frame()\n",
    "depth_intrin = depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "fx1, fy1, cx1, cy1 = depth_intrin.fx, depth_intrin.fy, depth_intrin.ppx, depth_intrin.ppy\n",
    "dist_coeffs1 = depth_intrin.coeffs  # 畸变系数\n",
    "dist_coeffs1 = np.array(dist_coeffs1)\n",
    "\n",
    "# 停止管道\n",
    "pipeline.stop()\n",
    "\n",
    "K = np.array([\n",
    "    [fx, 0, cx],\n",
    "    [0, fy, cy],\n",
    "    [0, 0, 1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(color_intrin, '\\n', fx, fy, cx, cy, dist_coeffs, '\\n', K)\n",
    "print(depth_intrin, '\\n', fx1, fy1, cx1, cy1, dist_coeffs1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graspnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
